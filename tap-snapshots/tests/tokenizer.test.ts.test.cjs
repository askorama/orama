/* IMPORTANT
 * This snapshot file is auto-generated, but designed for humans.
 * It should be checked into source control and tracked carefully.
 * Re-generate by setting TAP_SNAPSHOT=1 and running tests.
 * Make sure to inspect the output below.  Do not ignore changes!
 */
'use strict'
exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in dutch > Should tokenize and stem correctly in dutch-O1 1`] = `
Array [
  "de",
  "kleine",
  "koeien",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in dutch > Should tokenize and stem correctly in dutch-O2 1`] = `
Array [
  "ik",
  "heb",
  "wat",
  "taarten",
  "gemaakt",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english > Should tokenize and stem correctly in english-O1 1`] = `
Array [
  "the",
  "quick",
  "brown",
  "fox",
  "jumps",
  "over",
  "lazy",
  "dog",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english > Should tokenize and stem correctly in english-O2 1`] = `
Array [
  "i",
  "baked",
  "some",
  "cakes",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english and allow duplicates > Should tokenize and stem correctly in english and allow duplicates-O1 1`] = `
Array [
  "this",
  "is",
  "a",
  "test",
  "with",
  "duplicates",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english and allow duplicates > Should tokenize and stem correctly in english and allow duplicates-O2 1`] = `
Array [
  "it's",
  "alive",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in french > Should tokenize and stem correctly in french-O1 1`] = `
Array [
  "voyons",
  "quel",
  "temps",
  "il",
  "fait",
  "dehors",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in french > Should tokenize and stem correctly in french-O2 1`] = `
Array [
  "j",
  "ai",
  "fait",
  "des",
  "gateaux",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in italian > Should tokenize and stem correctly in italian-O1 1`] = `
Array [
  "ho",
  "cucinato",
  "delle",
  "torte",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in italian > Should tokenize and stem correctly in italian-O2 1`] = `
Array [
  "dormire",
  "una",
  "cosa",
  "difficile",
  "quando",
  "i",
  "test",
  "non",
  "passano",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in norwegian > Should tokenize and stem correctly in norwegian-O1 1`] = `
Array [
  "jeg",
  "kokte",
  "noen",
  "kaker",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in norwegian > Should tokenize and stem correctly in norwegian-O2 1`] = `
Array [
  "a",
  "sove",
  "er",
  "en",
  "vanskelig",
  "ting",
  "nar",
  "testene",
  "mislykkes",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in portuguese > Should tokenize and stem correctly in portuguese-O1 1`] = `
Array [
  "eu",
  "cozinhei",
  "alguns",
  "bolos",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in portuguese > Should tokenize and stem correctly in portuguese-O2 1`] = `
Array [
  "dormir",
  "e",
  "uma",
  "coisa",
  "dificil",
  "quando",
  "os",
  "testes",
  "falham",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in russian > Should tokenize and stem correctly in russian-O1 1`] = `
Array [
  "я",
  "приготовила",
  "пирожные",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in russian > Should tokenize and stem correctly in russian-O2 1`] = `
Array [
  "спать",
  "трудно",
  "когда",
  "тесты",
  "не",
  "срабатывают",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in spanish > Should tokenize and stem correctly in spanish-O1 1`] = `
Array [
  "cocine",
  "unos",
  "pasteles",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in spanish > Should tokenize and stem correctly in spanish-O2 1`] = `
Array [
  "dormir",
  "es",
  "algo",
  "dificil",
  "cuando",
  "las",
  "pruebas",
  "fallan",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in swedish > Should tokenize and stem correctly in swedish-O1 1`] = `
Array [
  "jag",
  "lagade",
  "nagra",
  "kakor",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in swedish > Should tokenize and stem correctly in swedish-O2 1`] = `
Array [
  "att",
  "sova",
  "ar",
  "en",
  "svar",
  "sak",
  "nar",
  "testerna",
  "misslyckas",
]
`
